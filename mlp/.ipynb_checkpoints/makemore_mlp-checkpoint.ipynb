{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a3382a3-7692-4495-a34e-dfa0c242c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd2e07b1-4f12-48c0-87d1-21958595a7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "543164df-74fb-4642-a2b1-96b7b200e265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd5b7235-6509-4577-baa3-791320c33d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers in alphabetical order\n",
    "chars = sorted(list(set(\"\".join(words)))) # because each letter of the alphabet is used at least once in the entire dataset, we just get the alphabet here.\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f5e303d-546e-4861-8817-3d405fd831f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "=======================\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "=======================\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "=======================\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "=======================\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: take the n first chars to predict the (n+1)th char.\n",
    "X, Y = [], []\n",
    "for w in words[:5]: # lets just work with the first five words temporarily.\n",
    "\n",
    "    print(\"=======================\")\n",
    "    print(w)\n",
    "    context = [0] * block_size # padding\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(\"\".join(itos[i] for i in context), \"--->\", itos[ix]) # this is just for us to understand the rolling window mechanism going on here.\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y) # much easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45684c59-46ec-4c37-89d5-fcb506dd043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 15],\n",
      "        [ 0, 15, 12],\n",
      "        [15, 12,  9],\n",
      "        [12,  9, 22],\n",
      "        [ 9, 22,  9],\n",
      "        [22,  9,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  1],\n",
      "        [ 0,  1, 22],\n",
      "        [ 1, 22,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  9],\n",
      "        [ 0,  9, 19],\n",
      "        [ 9, 19,  1],\n",
      "        [19,  1,  2],\n",
      "        [ 1,  2,  5],\n",
      "        [ 2,  5, 12],\n",
      "        [ 5, 12, 12],\n",
      "        [12, 12,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 19],\n",
      "        [ 0, 19, 15],\n",
      "        [19, 15, 16],\n",
      "        [15, 16,  8],\n",
      "        [16,  8,  9],\n",
      "        [ 8,  9,  1]]) torch.int64 torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at X and Y.\n",
    "print(X, X.dtype, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75fc70b9-ee87-486c-8c11-0ed9fc031f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]) torch.int64 torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(Y, Y.dtype, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb33532b-a232-4b72-a8cc-7475e5168000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEach 3-sized example we got from the first five words yielded this tensor X with\\na numerical 'translation' of each character in the example. And Y gives us what\\neach example is being mapped to.\\n\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Each 3-sized example we got from the first five words yielded this tensor X with\n",
    "a numerical 'translation' of each character in the example. And Y gives us what\n",
    "each example is being mapped to.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7732534c-3809-4e34-bc4f-6dc5b4dc75b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.5225, -0.0693],\n",
       "         [ 0.9991,  0.6877],\n",
       "         [-0.0084, -0.5852],\n",
       "         [ 1.2244,  1.8130],\n",
       "         [-0.0543,  0.1134],\n",
       "         [ 1.2541,  0.0716],\n",
       "         [-0.5010, -1.5812],\n",
       "         [-1.0269,  0.3056],\n",
       "         [ 0.7188, -1.0200],\n",
       "         [ 0.1073,  0.9782],\n",
       "         [ 0.6673,  0.6456],\n",
       "         [ 0.6544,  0.4970],\n",
       "         [-0.7659, -1.0119],\n",
       "         [ 0.4284,  1.3518],\n",
       "         [ 0.2509,  0.7649],\n",
       "         [ 0.1449,  0.6591],\n",
       "         [-1.9750,  0.4480],\n",
       "         [ 1.3065,  0.4241],\n",
       "         [-0.3795, -2.3439],\n",
       "         [-1.0627,  1.3774],\n",
       "         [ 1.1348,  1.0579],\n",
       "         [ 0.8643, -0.3144],\n",
       "         [-1.3033,  0.5717],\n",
       "         [ 1.6092,  1.5165],\n",
       "         [ 2.5329, -2.0169],\n",
       "         [ 1.2034, -0.5325],\n",
       "         [ 0.4753, -0.4789]]),\n",
       " torch.Size([27, 2]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "'''\n",
    "Now, we essentially have an embedding C: Alphabet -->Â R^2 that lets us take a char\n",
    "and place it in some space. With this space, we can see how certain characters\n",
    "might be \"closer\" to others in that space, which could indicate some sort of semantic\n",
    "\"closeness\". However, this may or may not be blackbox, i.e. we don't really know\n",
    "how or why certain characters might be closer to each other than others. I don't know,\n",
    "though, that's just what I think.\n",
    "'''\n",
    "C, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0756c86-bb46-433a-baab-8b9c827d8098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNow, we could potentially just use C and index into it as a lookup table, i.e.\\nC[5] = tensor([0.1615, 1.3169]), and so the character \"e\", the fifth in the alphabet,\\nwould be embedded as that vector in R^2. However, there\\'s a more interesting way to\\ndo this which could change the way we consider a layer in our NN, and that is by\\nusing one-hot encoding.\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Now, we could potentially just use C and index into it as a lookup table, i.e.\n",
    "C[5] = tensor([0.1615, 1.3169]), and so the character \"e\", the fifth in the alphabet,\n",
    "would be embedded as that vector in R^2. However, there's a more interesting way to\n",
    "do this which could change the way we consider a layer in our NN, and that is by\n",
    "using one-hot encoding.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c014d335-5576-4d6d-aeef-3fa34df2f962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C == C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "724231ee-90d3-49cd-b9cf-14cedac6e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effectively, because of how matrix multiplication works, these are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec5e8f76-804a-4081-8a6f-f540ab6d019e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 1.2541,  0.0716]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 1.2541,  0.0716],\n",
       "          [ 0.4284,  1.3518]],\n",
       " \n",
       "         [[ 1.2541,  0.0716],\n",
       "          [ 0.4284,  1.3518],\n",
       "          [ 0.4284,  1.3518]],\n",
       " \n",
       "         [[ 0.4284,  1.3518],\n",
       "          [ 0.4284,  1.3518],\n",
       "          [ 0.9991,  0.6877]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 0.1449,  0.6591]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 0.1449,  0.6591],\n",
       "          [-0.7659, -1.0119]],\n",
       " \n",
       "         [[ 0.1449,  0.6591],\n",
       "          [-0.7659, -1.0119],\n",
       "          [ 0.1073,  0.9782]],\n",
       " \n",
       "         [[-0.7659, -1.0119],\n",
       "          [ 0.1073,  0.9782],\n",
       "          [-1.3033,  0.5717]],\n",
       " \n",
       "         [[ 0.1073,  0.9782],\n",
       "          [-1.3033,  0.5717],\n",
       "          [ 0.1073,  0.9782]],\n",
       " \n",
       "         [[-1.3033,  0.5717],\n",
       "          [ 0.1073,  0.9782],\n",
       "          [ 0.9991,  0.6877]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 0.9991,  0.6877]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 0.9991,  0.6877],\n",
       "          [-1.3033,  0.5717]],\n",
       " \n",
       "         [[ 0.9991,  0.6877],\n",
       "          [-1.3033,  0.5717],\n",
       "          [ 0.9991,  0.6877]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 0.1073,  0.9782]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 0.1073,  0.9782],\n",
       "          [-1.0627,  1.3774]],\n",
       " \n",
       "         [[ 0.1073,  0.9782],\n",
       "          [-1.0627,  1.3774],\n",
       "          [ 0.9991,  0.6877]],\n",
       " \n",
       "         [[-1.0627,  1.3774],\n",
       "          [ 0.9991,  0.6877],\n",
       "          [-0.0084, -0.5852]],\n",
       " \n",
       "         [[ 0.9991,  0.6877],\n",
       "          [-0.0084, -0.5852],\n",
       "          [ 1.2541,  0.0716]],\n",
       " \n",
       "         [[-0.0084, -0.5852],\n",
       "          [ 1.2541,  0.0716],\n",
       "          [-0.7659, -1.0119]],\n",
       " \n",
       "         [[ 1.2541,  0.0716],\n",
       "          [-0.7659, -1.0119],\n",
       "          [-0.7659, -1.0119]],\n",
       " \n",
       "         [[-0.7659, -1.0119],\n",
       "          [-0.7659, -1.0119],\n",
       "          [ 0.9991,  0.6877]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [ 2.5225, -0.0693],\n",
       "          [-1.0627,  1.3774]],\n",
       " \n",
       "         [[ 2.5225, -0.0693],\n",
       "          [-1.0627,  1.3774],\n",
       "          [ 0.1449,  0.6591]],\n",
       " \n",
       "         [[-1.0627,  1.3774],\n",
       "          [ 0.1449,  0.6591],\n",
       "          [-1.9750,  0.4480]],\n",
       " \n",
       "         [[ 0.1449,  0.6591],\n",
       "          [-1.9750,  0.4480],\n",
       "          [ 0.7188, -1.0200]],\n",
       " \n",
       "         [[-1.9750,  0.4480],\n",
       "          [ 0.7188, -1.0200],\n",
       "          [ 0.1073,  0.9782]],\n",
       " \n",
       "         [[ 0.7188, -1.0200],\n",
       "          [ 0.1073,  0.9782],\n",
       "          [ 0.9991,  0.6877]]]),\n",
       " torch.Size([32, 3, 2]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In pytorch, you can index into tensors with tensors.\n",
    "C[X], C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "291ce5ae-e26f-4e69-b5e1-39257537b97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis essentially yielded a 3 dimensional tensor, where in the first dimension,\\nwe have 32 rows for each example, in the second dimension, we have 3 characters\\nfrom a given example, and in the third dimension, we have 2 numbers representing\\nthe \"location\" in R^2 of a given character. So, effectively, our embedding is C[x].\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This essentially yielded a 3 dimensional tensor, where in the first dimension,\n",
    "we have 32 rows for each example, in the second dimension, we have 3 characters\n",
    "from a given example, and in the third dimension, we have 2 numbers representing\n",
    "the \"location\" in R^2 of a given character. So, effectively, our embedding is C[x].\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ed717dd-1572-4f1b-b1bb-8eb38923afa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fb12c42-6afa-43e1-9ba9-dec81f45ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the weights and biases of our first layer.\n",
    "W1 = torch.randn((6,100)) # 100 comes from the design choice to have 100 neurons in this layer.\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6f72cb2-e6d3-451a-b987-754b4933a0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4221e+00,  3.7419e+00,  4.4712e+00,  ..., -2.3295e+00,\n",
       "          -6.7468e+00, -4.7674e+00],\n",
       "         [ 2.3230e+00,  3.9573e+00,  2.9480e+00,  ..., -1.5265e+00,\n",
       "          -5.6410e+00, -5.7813e+00],\n",
       "         [-7.8069e-01,  4.0699e+00,  2.5567e+00,  ..., -3.1416e+00,\n",
       "          -2.7711e+00, -8.1525e+00],\n",
       "         ...,\n",
       "         [-4.1044e+00, -4.9766e-03, -1.7445e+00,  ..., -5.4382e-01,\n",
       "           9.5053e-01, -1.5830e-01],\n",
       "         [ 2.5567e+00, -1.3451e+00,  9.0445e+00,  ..., -4.5168e+00,\n",
       "           3.3268e-01,  5.1478e+00],\n",
       "         [-2.6698e+00, -4.5450e-01,  4.5280e-01,  ..., -2.0475e+00,\n",
       "          -4.4025e+00, -2.1108e+00]]),\n",
       " torch.Size([32, 100]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's concatenate the dimension containing n from R^n to match the number of rows in W1, so that we can do embedding @ W1.\n",
    "h = emb.view(-1,6) @ W1 + b1 # -1 allows torch to infer the size. It is in this case emb.shape[0] == 32, we're just trying to avoid hardcoding, because we just happened to have 32 examples right now given we're only looking at 5 words.\n",
    "h, h.shape, h.dtype\n",
    "# btw, emb.view(-1,6) @ W1 gives a 32 x 100 matrix, and we are trying to add to it a vector with 100 elements. This will work because of pytorch broadcasting, and it will do it in a way that is what we are indeed looking for in terms of linear combinations.\n",
    "# 32, 100\n",
    "#  1, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5df95a40-c9eb-410d-97c5-da12ecdded17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8900,  0.9989,  0.9997,  ..., -0.9812, -1.0000, -0.9999],\n",
       "        [ 0.9810,  0.9993,  0.9945,  ..., -0.9098, -1.0000, -1.0000],\n",
       "        [-0.6531,  0.9994,  0.9880,  ..., -0.9963, -0.9922, -1.0000],\n",
       "        ...,\n",
       "        [-0.9995, -0.0050, -0.9407,  ..., -0.4959,  0.7400, -0.1570],\n",
       "        [ 0.9880, -0.8729,  1.0000,  ..., -0.9998,  0.3209,  0.9999],\n",
       "        [-0.9905, -0.4256,  0.4242,  ..., -0.9672, -0.9997, -0.9711]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's also apply non-linearity in our layer before passing it on.\n",
    "h = torch.tanh(h)\n",
    "h # now we have nice values between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e8f8031-5ed8-4d56-9bcc-acebcdcbaabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "562c9fb5-aa1f-4403-948d-e296a0e40e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next layer:\n",
    "W2 = torch.randn((100, 27)) # input: 100 neurons. output: 27 neurons (last)\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1970dd6f-a8cd-470e-bfac-1e6b58442e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2 # this should work because dimensionality matches up + broadcasting works correctly for biases\n",
    "# logits are what we're about to pass into softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1eb7a66c-c341-4ff5-9173-0c08302f7ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "909b2db7-40c0-4e44-81bc-b7db35a618c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.6159e-09, 6.7762e-02, 2.7239e-06, 2.9769e-08, 1.7057e-04, 1.9661e-14,\n",
       "          1.7871e-07, 8.9337e-06, 1.0338e-09, 1.6759e-08, 5.1723e-12, 8.0536e-01,\n",
       "          2.2580e-05, 7.2072e-06, 4.8689e-03, 3.7948e-08, 1.0234e-09, 2.2641e-07,\n",
       "          6.0748e-07, 7.5104e-09, 3.1396e-13, 1.2148e-01, 7.7917e-06, 8.5659e-10,\n",
       "          1.8804e-04, 1.2436e-04, 4.5828e-08],\n",
       "         [5.4379e-12, 1.3090e-03, 6.3864e-07, 1.7082e-10, 4.6328e-04, 5.4002e-14,\n",
       "          4.6247e-08, 6.5736e-06, 4.3702e-11, 6.5085e-06, 5.7275e-11, 2.3638e-01,\n",
       "          6.0987e-07, 1.1333e-05, 8.1922e-05, 1.2730e-09, 2.8251e-09, 1.0835e-08,\n",
       "          2.5659e-09, 6.7349e-08, 1.1867e-14, 7.6116e-01, 2.3256e-05, 5.4611e-12,\n",
       "          5.5339e-04, 1.8214e-07, 4.3614e-09],\n",
       "         [3.1911e-15, 9.1824e-11, 1.2004e-08, 9.9191e-18, 1.6989e-10, 2.0257e-18,\n",
       "          4.0182e-15, 6.4535e-10, 3.3458e-16, 6.5842e-08, 7.4884e-10, 9.1915e-08,\n",
       "          1.6554e-05, 6.9101e-09, 1.9862e-10, 3.3622e-14, 1.8813e-14, 7.9484e-10,\n",
       "          1.3686e-10, 3.0499e-09, 1.9733e-16, 9.9998e-01, 7.1386e-08, 4.6651e-14,\n",
       "          6.4842e-11, 1.3097e-14, 2.7971e-11],\n",
       "         [2.1642e-11, 3.0133e-06, 8.9088e-08, 4.0614e-15, 2.6424e-08, 7.3211e-16,\n",
       "          2.4021e-09, 2.4286e-04, 7.0571e-19, 8.4737e-06, 2.4263e-04, 7.1989e-09,\n",
       "          1.9219e-02, 1.6007e-07, 2.7902e-10, 3.7294e-04, 5.6863e-10, 3.3607e-07,\n",
       "          1.3268e-08, 7.8507e-04, 4.3288e-08, 1.4408e-01, 8.3550e-02, 6.1615e-08,\n",
       "          7.5149e-01, 1.6552e-10, 8.9731e-06],\n",
       "         [4.3160e-08, 5.6159e-11, 4.4028e-08, 4.2678e-09, 2.0508e-08, 2.7051e-12,\n",
       "          5.9086e-05, 1.7356e-02, 1.2759e-11, 4.9204e-05, 7.2965e-04, 1.4430e-05,\n",
       "          1.3390e-01, 6.1107e-08, 7.4459e-08, 2.1938e-03, 4.7938e-09, 1.4857e-10,\n",
       "          4.4696e-07, 2.0515e-05, 1.7023e-02, 5.5595e-01, 1.2497e-01, 5.6852e-03,\n",
       "          1.3929e-01, 1.0446e-08, 2.7663e-03],\n",
       "         [4.6159e-09, 6.7762e-02, 2.7239e-06, 2.9769e-08, 1.7057e-04, 1.9661e-14,\n",
       "          1.7871e-07, 8.9337e-06, 1.0338e-09, 1.6759e-08, 5.1723e-12, 8.0536e-01,\n",
       "          2.2580e-05, 7.2072e-06, 4.8689e-03, 3.7948e-08, 1.0234e-09, 2.2641e-07,\n",
       "          6.0748e-07, 7.5104e-09, 3.1396e-13, 1.2148e-01, 7.7917e-06, 8.5659e-10,\n",
       "          1.8804e-04, 1.2436e-04, 4.5828e-08],\n",
       "         [1.1567e-13, 2.5015e-07, 9.3459e-08, 3.0881e-16, 1.2055e-05, 1.7246e-13,\n",
       "          3.4695e-12, 3.2043e-08, 5.1165e-13, 1.8555e-05, 2.8706e-07, 1.5598e-03,\n",
       "          2.9072e-06, 2.1089e-06, 5.8419e-08, 4.2474e-13, 1.4693e-08, 5.2891e-09,\n",
       "          2.4717e-09, 7.8530e-08, 5.2982e-15, 9.9835e-01, 5.2321e-05, 9.1538e-16,\n",
       "          2.4528e-06, 6.8934e-12, 8.7381e-09],\n",
       "         [8.1242e-14, 3.0994e-04, 2.4054e-05, 3.2295e-11, 8.1391e-08, 8.1384e-08,\n",
       "          1.6297e-10, 4.2643e-10, 1.1339e-09, 1.2494e-05, 8.2556e-11, 6.5408e-09,\n",
       "          5.8721e-10, 1.9754e-06, 1.7230e-10, 9.9394e-01, 3.1832e-10, 1.2896e-07,\n",
       "          3.0258e-12, 2.5873e-09, 2.8699e-12, 6.1191e-07, 1.3553e-07, 5.7091e-03,\n",
       "          8.4150e-07, 2.3955e-08, 1.9914e-14],\n",
       "         [1.8054e-10, 1.2125e-11, 1.0943e-06, 2.1044e-08, 3.9109e-08, 6.8698e-08,\n",
       "          6.7277e-05, 1.5684e-07, 3.0353e-07, 2.3963e-01, 2.0541e-07, 9.3028e-03,\n",
       "          5.3278e-04, 4.8502e-06, 1.1582e-03, 5.1730e-04, 1.3229e-07, 3.9399e-10,\n",
       "          8.4894e-03, 2.8084e-04, 2.9003e-01, 4.1231e-01, 7.8411e-05, 3.7502e-02,\n",
       "          4.1614e-10, 1.3323e-13, 8.7615e-05],\n",
       "         [1.9991e-05, 6.4997e-05, 7.3052e-03, 1.6365e-13, 2.9479e-08, 1.3477e-05,\n",
       "          7.9204e-13, 1.3334e-04, 3.7612e-12, 3.3796e-01, 3.2879e-03, 3.2445e-16,\n",
       "          5.9777e-04, 4.9083e-07, 1.0690e-08, 2.9114e-06, 2.3960e-02, 6.0697e-01,\n",
       "          2.3498e-05, 3.0194e-07, 1.9661e-02, 1.4658e-08, 4.6722e-08, 3.9185e-07,\n",
       "          6.5513e-08, 1.5681e-10, 2.0541e-08],\n",
       "         [2.7064e-07, 8.3536e-14, 2.3778e-10, 2.6071e-09, 1.4737e-11, 3.5763e-12,\n",
       "          2.1095e-08, 7.1032e-01, 1.9238e-12, 9.5290e-04, 3.8292e-08, 2.3781e-11,\n",
       "          7.9411e-05, 1.7741e-10, 1.6128e-08, 4.8376e-07, 7.2353e-12, 8.4088e-15,\n",
       "          2.1800e-11, 1.1165e-07, 1.3567e-01, 1.2472e-06, 1.9880e-07, 1.5297e-01,\n",
       "          2.2537e-14, 2.7889e-14, 7.7303e-10],\n",
       "         [5.6408e-05, 1.7118e-15, 1.3375e-08, 5.9235e-11, 1.6140e-08, 9.5918e-14,\n",
       "          8.3195e-08, 9.9956e-01, 9.0326e-15, 1.2431e-05, 2.3868e-06, 2.5902e-11,\n",
       "          1.8006e-05, 1.1188e-13, 6.8217e-14, 1.2365e-04, 4.4579e-07, 4.8529e-10,\n",
       "          2.2024e-08, 3.5576e-10, 2.2228e-04, 5.2522e-09, 1.9669e-07, 3.4038e-06,\n",
       "          1.1617e-08, 9.1965e-11, 2.3696e-06],\n",
       "         [4.6159e-09, 6.7762e-02, 2.7239e-06, 2.9769e-08, 1.7057e-04, 1.9661e-14,\n",
       "          1.7871e-07, 8.9337e-06, 1.0338e-09, 1.6759e-08, 5.1723e-12, 8.0536e-01,\n",
       "          2.2580e-05, 7.2072e-06, 4.8689e-03, 3.7948e-08, 1.0234e-09, 2.2641e-07,\n",
       "          6.0748e-07, 7.5104e-09, 3.1396e-13, 1.2148e-01, 7.7917e-06, 8.5659e-10,\n",
       "          1.8804e-04, 1.2436e-04, 4.5828e-08],\n",
       "         [2.0147e-12, 7.0861e-07, 9.9974e-08, 5.0647e-14, 1.0863e-05, 2.1742e-16,\n",
       "          1.0238e-10, 1.2778e-07, 1.1024e-13, 4.4333e-07, 3.2217e-10, 4.3962e-03,\n",
       "          7.2117e-05, 3.9976e-07, 6.0388e-06, 2.4040e-13, 2.0822e-11, 2.4486e-09,\n",
       "          6.2829e-10, 2.5962e-08, 6.3108e-14, 9.9548e-01, 8.6622e-06, 1.6532e-15,\n",
       "          2.8937e-05, 1.1741e-10, 5.9878e-09],\n",
       "         [1.0512e-10, 9.2923e-07, 1.3283e-01, 4.1545e-15, 8.8263e-08, 4.8871e-07,\n",
       "          3.2262e-12, 3.7482e-06, 4.5823e-11, 3.3018e-04, 5.4470e-03, 1.2039e-04,\n",
       "          3.7867e-05, 8.5128e-06, 1.2105e-08, 2.3733e-05, 2.3517e-07, 2.0986e-05,\n",
       "          2.1783e-09, 1.0290e-06, 1.5102e-08, 8.5588e-01, 5.2985e-03, 1.9739e-07,\n",
       "          1.0236e-06, 1.2478e-11, 7.0527e-08],\n",
       "         [1.9824e-09, 1.2304e-10, 1.0983e-07, 5.7742e-07, 4.2677e-08, 5.7038e-13,\n",
       "          2.4472e-05, 1.0399e-03, 1.5481e-12, 4.4670e-06, 3.6508e-09, 6.0663e-06,\n",
       "          5.9130e-04, 7.1078e-10, 4.9066e-08, 9.0617e-04, 3.8352e-14, 1.2094e-14,\n",
       "          2.7318e-06, 1.1316e-07, 4.9272e-03, 3.0608e-04, 3.3911e-04, 9.9185e-01,\n",
       "          1.3118e-11, 2.0030e-10, 3.5903e-10],\n",
       "         [4.6159e-09, 6.7762e-02, 2.7239e-06, 2.9769e-08, 1.7057e-04, 1.9661e-14,\n",
       "          1.7871e-07, 8.9337e-06, 1.0338e-09, 1.6759e-08, 5.1723e-12, 8.0536e-01,\n",
       "          2.2580e-05, 7.2072e-06, 4.8689e-03, 3.7948e-08, 1.0234e-09, 2.2641e-07,\n",
       "          6.0748e-07, 7.5104e-09, 3.1396e-13, 1.2148e-01, 7.7917e-06, 8.5659e-10,\n",
       "          1.8804e-04, 1.2436e-04, 4.5828e-08],\n",
       "         [1.9537e-13, 7.5855e-08, 3.5743e-08, 1.0006e-16, 4.8402e-06, 1.3348e-14,\n",
       "          1.8378e-13, 1.9762e-08, 9.1604e-14, 2.6433e-06, 1.4026e-06, 9.8942e-04,\n",
       "          1.3151e-05, 8.4605e-07, 1.8253e-07, 1.1535e-13, 7.6515e-09, 2.3029e-08,\n",
       "          9.8262e-09, 9.6731e-08, 2.4765e-14, 9.9895e-01, 2.8663e-05, 5.4794e-16,\n",
       "          5.0191e-06, 5.1230e-12, 1.7033e-08],\n",
       "         [5.1243e-11, 4.8128e-09, 4.6841e-04, 5.7311e-17, 2.8236e-12, 1.5581e-10,\n",
       "          3.7560e-12, 7.4996e-07, 1.2110e-15, 4.7856e-06, 1.8533e-05, 2.1134e-09,\n",
       "          4.4736e-08, 4.3695e-05, 7.2503e-15, 8.6823e-07, 8.6126e-12, 1.2083e-08,\n",
       "          2.8963e-12, 2.3819e-07, 2.1385e-11, 9.9944e-01, 1.8044e-05, 2.0470e-08,\n",
       "          5.7050e-10, 1.0231e-13, 3.3991e-09],\n",
       "         [2.2011e-07, 6.8655e-13, 5.5745e-11, 5.0829e-08, 2.2219e-08, 3.4702e-15,\n",
       "          7.6975e-08, 5.1225e-03, 6.5518e-15, 3.0335e-06, 3.8960e-06, 9.1860e-11,\n",
       "          4.7446e-04, 1.0913e-09, 1.4535e-10, 4.0490e-05, 6.8335e-13, 2.9486e-14,\n",
       "          1.5740e-10, 3.0896e-07, 1.9403e-02, 6.9663e-07, 1.5348e-05, 9.7494e-01,\n",
       "          2.2070e-11, 3.0516e-14, 8.7767e-10],\n",
       "         [1.6972e-03, 9.2062e-12, 4.4911e-08, 2.7100e-09, 2.5215e-09, 1.4356e-07,\n",
       "          3.2409e-05, 7.1315e-01, 6.1076e-08, 2.2822e-01, 5.9829e-07, 5.5113e-07,\n",
       "          7.3710e-09, 4.1897e-09, 6.6147e-11, 5.6334e-02, 1.7280e-04, 3.1196e-06,\n",
       "          1.3809e-07, 2.8841e-08, 1.0249e-04, 9.4630e-07, 1.4885e-05, 6.5638e-06,\n",
       "          1.3412e-08, 1.5893e-10, 2.5507e-04],\n",
       "         [2.0929e-11, 3.9179e-08, 2.9802e-06, 5.8736e-09, 3.3441e-06, 1.4705e-10,\n",
       "          4.4175e-06, 8.4859e-05, 2.0902e-07, 4.6477e-04, 5.1638e-11, 8.2625e-01,\n",
       "          1.1520e-03, 1.9344e-05, 9.4632e-07, 1.2914e-04, 8.5866e-09, 2.9306e-11,\n",
       "          1.9018e-03, 8.0754e-09, 5.7785e-06, 1.5472e-01, 1.6490e-07, 1.5255e-02,\n",
       "          8.5324e-10, 1.8911e-08, 1.1115e-09],\n",
       "         [2.4039e-09, 4.8202e-07, 2.6840e-07, 7.8243e-14, 1.2230e-07, 1.0053e-03,\n",
       "          2.2740e-11, 1.6952e-07, 3.1643e-11, 8.4956e-05, 1.7421e-08, 3.9300e-11,\n",
       "          5.7003e-07, 2.1586e-08, 9.8787e-12, 6.0402e-03, 4.1634e-02, 9.5123e-01,\n",
       "          2.6407e-06, 8.0714e-10, 3.7663e-11, 3.2986e-07, 7.8367e-13, 2.8128e-07,\n",
       "          7.6600e-07, 2.1570e-08, 1.1274e-13],\n",
       "         [2.3439e-12, 1.7002e-07, 2.3074e-07, 2.8836e-06, 2.6953e-07, 2.6872e-01,\n",
       "          3.3748e-09, 1.8135e-09, 3.9016e-03, 1.1069e-04, 1.4750e-13, 1.6134e-01,\n",
       "          1.5463e-10, 1.9051e-01, 3.2502e-03, 5.6468e-05, 2.7591e-08, 2.9133e-09,\n",
       "          6.0715e-06, 2.6204e-07, 1.4747e-05, 3.3936e-01, 1.6960e-11, 3.2471e-02,\n",
       "          1.1428e-09, 2.5574e-04, 9.6076e-15],\n",
       "         [1.3299e-11, 1.2371e-10, 2.2609e-08, 3.2008e-11, 1.8426e-10, 9.9335e-13,\n",
       "          1.7691e-15, 3.0455e-14, 1.1430e-05, 2.4597e-05, 2.0399e-11, 2.4587e-10,\n",
       "          1.4530e-03, 6.4316e-11, 3.3625e-08, 8.4193e-10, 7.6418e-09, 1.3672e-05,\n",
       "          9.9843e-01, 1.5428e-06, 1.5476e-07, 6.8704e-05, 6.0180e-14, 6.2318e-11,\n",
       "          1.3413e-13, 7.3042e-14, 1.8618e-11],\n",
       "         [4.6159e-09, 6.7762e-02, 2.7239e-06, 2.9769e-08, 1.7057e-04, 1.9661e-14,\n",
       "          1.7871e-07, 8.9337e-06, 1.0338e-09, 1.6759e-08, 5.1723e-12, 8.0536e-01,\n",
       "          2.2580e-05, 7.2072e-06, 4.8689e-03, 3.7948e-08, 1.0234e-09, 2.2641e-07,\n",
       "          6.0748e-07, 7.5104e-09, 3.1396e-13, 1.2148e-01, 7.7917e-06, 8.5659e-10,\n",
       "          1.8804e-04, 1.2436e-04, 4.5828e-08],\n",
       "         [2.5912e-12, 2.6109e-05, 3.3788e-07, 1.3599e-15, 4.5616e-07, 6.5300e-11,\n",
       "          6.9211e-15, 2.6065e-07, 2.9759e-12, 6.3270e-05, 1.0322e-04, 2.8472e-03,\n",
       "          1.1931e-05, 1.0250e-06, 3.2484e-06, 1.5408e-11, 1.2200e-05, 9.5169e-07,\n",
       "          3.2024e-07, 7.3480e-06, 1.3793e-10, 9.9365e-01, 3.2480e-03, 7.9783e-15,\n",
       "          2.5016e-05, 4.7635e-13, 2.2327e-06],\n",
       "         [6.1961e-12, 5.3341e-08, 1.4831e-06, 1.6480e-12, 9.2005e-10, 8.8220e-13,\n",
       "          1.0668e-09, 4.4118e-07, 1.1035e-15, 2.0407e-08, 1.2729e-07, 1.5136e-10,\n",
       "          2.3222e-09, 6.6928e-07, 8.8428e-17, 9.9923e-01, 2.8873e-15, 2.5415e-11,\n",
       "          5.2869e-12, 1.7160e-09, 9.0394e-11, 3.8784e-04, 2.6049e-04, 1.2230e-04,\n",
       "          1.3029e-10, 7.8180e-11, 1.3755e-14],\n",
       "         [1.4756e-06, 4.4283e-13, 3.4876e-10, 2.4311e-15, 1.5972e-12, 5.4911e-06,\n",
       "          4.4638e-09, 9.9748e-01, 4.9503e-11, 8.5595e-06, 4.5264e-05, 9.8994e-13,\n",
       "          1.5813e-10, 1.7737e-07, 3.8320e-12, 1.7962e-09, 9.2326e-04, 2.6582e-10,\n",
       "          1.1635e-11, 8.1528e-10, 1.5388e-03, 3.1046e-08, 1.0896e-09, 4.3266e-09,\n",
       "          2.2988e-13, 2.2874e-13, 6.6420e-07],\n",
       "         [1.0281e-11, 1.5189e-14, 1.9810e-12, 7.8852e-07, 1.3931e-09, 2.8525e-10,\n",
       "          9.4893e-12, 1.7492e-10, 1.6118e-09, 1.2548e-08, 6.2353e-16, 2.5612e-14,\n",
       "          6.4426e-14, 1.2708e-09, 1.4003e-18, 4.8265e-06, 1.0701e-17, 3.3263e-12,\n",
       "          2.6720e-13, 3.9483e-12, 5.1764e-09, 6.6517e-12, 7.9815e-11, 9.9999e-01,\n",
       "          3.0240e-20, 2.3130e-15, 1.1031e-17],\n",
       "         [3.5962e-07, 1.8643e-11, 4.2392e-08, 3.6118e-11, 2.0373e-09, 1.8946e-10,\n",
       "          7.6335e-09, 2.4602e-05, 1.7499e-07, 2.6035e-05, 4.0918e-07, 3.5104e-09,\n",
       "          2.3557e-04, 1.5643e-11, 1.5491e-03, 3.3383e-07, 1.7279e-02, 2.2014e-09,\n",
       "          2.6594e-05, 4.5239e-08, 9.8077e-01, 3.0824e-08, 1.2160e-07, 1.4253e-10,\n",
       "          1.3463e-09, 2.9489e-12, 8.5174e-05],\n",
       "         [7.6911e-11, 1.5348e-04, 2.3334e-04, 2.0922e-13, 3.3649e-05, 3.3603e-15,\n",
       "          3.1640e-12, 8.5738e-08, 3.8765e-16, 2.2896e-06, 3.9825e-06, 5.2686e-06,\n",
       "          9.0854e-01, 1.4360e-08, 8.5456e-11, 1.5529e-02, 5.2946e-08, 1.4357e-04,\n",
       "          2.9120e-03, 1.4579e-05, 2.9956e-08, 7.2029e-02, 1.7891e-04, 3.1418e-08,\n",
       "          2.2261e-04, 3.1566e-11, 1.0903e-09]]),\n",
       " torch.Size([32, 27]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "prob, prob.shape, prob[0].sum()\n",
    "# all the probabilities add to 1. We have just completed softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f66a6bc-70e9-4e5e-92bf-3ce3f839ad61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we'll see how correctly \"prob\" predicts the next character for a given example out of the 32 examples.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cf2e12fa-ccc0-4a98-8c54-a0832f7265e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll create an iterator over these values:\n",
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "10c1383f-5983-408d-bdb0-2c94d9846527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9661e-14, 1.1333e-05, 6.9101e-09, 3.0133e-06, 4.3160e-08, 3.7948e-08,\n",
       "        2.9072e-06, 1.2494e-05, 7.8411e-05, 3.3796e-01, 8.3536e-14, 5.6408e-05,\n",
       "        6.7762e-02, 8.6622e-06, 9.2923e-07, 1.9824e-09, 1.6759e-08, 9.6731e-08,\n",
       "        4.8128e-09, 5.5745e-11, 1.4356e-07, 1.1520e-03, 5.7003e-07, 1.7002e-07,\n",
       "        1.3299e-11, 7.5104e-09, 1.5408e-11, 2.8873e-15, 4.9503e-11, 1.2548e-08,\n",
       "        1.8643e-11, 7.6911e-11])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we'll index over prob with this and Y to see how confident our model was for a given correct output.\n",
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "40809e25-d056-4ffb-b1e8-487c8bae7308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.2685)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so ideally we want all of these to be 1. Right now these are all ready bad because we randomly assigned initially our weights and biases, i.e. the model is untrained.\n",
    "# Now, we can actually take the log of all of these, so that values closer to 0 are negative, and values closer to 1 are 0, so respectively punishing and rewarding the model.\n",
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss # this is our unified, single value to show how good or bad the model has done with the given parameters. Right now its terrible with a loss of 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f3521-a763-4010-9dda-3f09adc79f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
